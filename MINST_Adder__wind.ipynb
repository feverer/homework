{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业：手写数字加法机\n",
    "\n",
    "本文件是与集智AI学园出品的系列课程“火炬上的深度学习”配套的作业notebook。本作业要求学员构造一个卷积神经网，输入两张手写数字图片，输出这两个数字的和。\n",
    "\n",
    "本文件提供了一个完成做的大框架，学员需要自行修改、添加代码，从而完成任务\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第III课的配套源代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包，请保证torchvision已经在你的环境中安装好\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义需要用到的超参数\n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 20  #训练的总循环周期\n",
    "batch_size = 64\n",
    "\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor(),  #将图像转化为Tensor\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# 由于每一个样本需要输入两个图片，因此每一个loader和sampler都有两个\n",
    "\n",
    "sampler1 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.permutation(range(len(train_dataset))))\n",
    "sampler2 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.permutation(range(len(train_dataset))))\n",
    "\n",
    "# 训练数据的两个加载器\n",
    "train_loader1 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           sampler = sampler1\n",
    "                                           )\n",
    "train_loader2 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           sampler = sampler2\n",
    "                                           )\n",
    "\n",
    "# 校验数据和测试数据都各自有两套\n",
    "val_size = 5000\n",
    "val_indices1 = range(val_size)\n",
    "val_indices2 = np.random.permutation(range(val_size))\n",
    "test_indices1 = range(val_size, len(test_dataset))\n",
    "test_indices2 = np.random.permutation(test_indices1)\n",
    "val_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(val_indices1)\n",
    "val_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(val_indices2)\n",
    "\n",
    "test_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(test_indices1)\n",
    "test_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(test_indices2)\n",
    "\n",
    "val_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler1\n",
    "                                        )\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler2\n",
    "                                        )\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler1\n",
    "                                         )\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler2\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST Adder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现加法器，需要同时处理两个手写体数字图像，并对它进行相应的图像处理。因此，网络的架构为两个卷积神经网络，串联上两个全链接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = [4, 8]\n",
    "class MINSTAdder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MINSTAdder, self).__init__()\n",
    "        #处理第一个图像处理用的卷积网络部件\n",
    "        self.net1_conv1 = nn.Conv2d(1, 4, 5, padding = 2)\n",
    "        self.net_pool = nn.MaxPool2d(2, 2)\n",
    "        self.net1_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2)\n",
    "        \n",
    "        #处理第二个图像处理用的卷积网络部件\n",
    "        self.net2_conv1 = nn.Conv2d(1, 4, 5, padding = 2)\n",
    "        self.net2_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2)\n",
    "        \n",
    "        #后面的全连阶层\n",
    "        self.fc1 = nn.Linear(2 * image_size // 4 * image_size // 4 * depth[1] , 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)      \n",
    "\n",
    "    def forward(self, x, y, training = True):\n",
    "        #第一张图像的处理流程\n",
    "        x = F.relu(self.net1_conv1(x))\n",
    "        x = self.net_pool(x)\n",
    "        x = F.relu(self.net1_conv2(x))\n",
    "        x = self.net_pool(x)\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        \n",
    "        #第二张图像的处理流程\n",
    "        y = F.relu(self.net2_conv1(y))\n",
    "        y = self.net_pool(y)\n",
    "        y = F.relu(self.net2_conv2(y))\n",
    "        y = self.net_pool(y)\n",
    "        y = y.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        \n",
    "        #将前两部处理得到的张量并列到一起，喂给两层全链接前馈网络，最后输出预测数值\n",
    "        z = torch.cat((x, y), 1)      # 按行连接\n",
    "        z = self.fc1(z)\n",
    "        z = F.relu(z)\n",
    "        z = F.dropout(z, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "        z = self.fc2(z)\n",
    "        return z\n",
    "\n",
    "# 计算准确度的函数（有多少数字给出了严格的正确输出结果）\n",
    "def rightness(y, target):\n",
    "    rounded = torch.round(y).type(torch.LongTensor)\n",
    "    equal = rounded.squeeze().eq(target)\n",
    "    print(\"equal=\", equal)\n",
    "    out = equal.sum()         # out 应该是数值了\n",
    "    out1 = y.size()[0]\n",
    "    return(out, out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将网络定义为一个预测器，来对加法的结果进行预测，因此用MSE均方误差作为我们的损失函数\n",
    "net = MINSTAdder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal= Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.ByteTensor of size 64]\n",
      "\n",
      "right[0]= Variable containing:\n",
      " 2\n",
      "[torch.ByteTensor of size 1]\n",
      " \n",
      "right[1]= 64\n",
      "train_r= (Variable containing:\n",
      " 2\n",
      "[torch.ByteTensor of size 1]\n",
      ", 64)\n",
      "周期: 0 \tbatch: 0 \t训练误差: Variable containing:\n",
      " 99.6084\n",
      "[torch.FloatTensor of size 1]\n",
      " \t检验误差: Variable containing:\n",
      " 95.5140\n",
      "[torch.FloatTensor of size 1]\n",
      " \t准确率: Variable containing:\n",
      " 0\n",
      "[torch.ByteTensor of size 1]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.ByteTensor' object has no attribute 'neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be7fd1f9bde0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright_ratio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSubConstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/autograd/_functions/basic_ops.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, a, b, inplace)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.ByteTensor' object has no attribute 'neg'"
     ]
    }
   ],
   "source": [
    "# 开始训练循环，本部分代码需要补齐\n",
    "num_epochs = 20\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    train_rights = []\n",
    "    # 成对提取数据，我们的办法是通过zip命令，将loader1和2并列在一起，一对一对的读取数据\n",
    "    for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "        ((x1, y1), (x2, y2)) = data  #data是tensor\n",
    "        #print(\"data=\", data, \"\\n\")\n",
    "        \n",
    "        net.train()\n",
    "        outputs = net(Variable(x1), Variable(x2))\n",
    "        #print(\"outputs=\", outputs, \"\\n\")\n",
    "        \n",
    "        labels = y1 + y2\n",
    "        #print(\"labels=\", labels, \"\\n\")\n",
    "        \n",
    "        outputs = outputs.squeeze()\n",
    "        right = rightness(outputs, Variable(labels.type(torch.LongTensor)))\n",
    "        print(\"right[0]=\", right[0], \"\\nright[1]=\", right[1])\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        loss = criterion(outputs, Variable(labels.type(torch.FloatTensor)))   \n",
    "        #print(\"loss=\", loss, \"\\n\")\n",
    "        losses.append(loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_losses = []\n",
    "            \n",
    "            \n",
    "            for data in zip(val_loader1, val_loader2):\n",
    "                ((x1, y1), (x2, y2)) = data\n",
    "                output = net(Variable(x1), Variable(x2))\n",
    "                label = y1 + y2\n",
    "                loss = criterion(output, Variable(label.type(torch.FloatTensor)))   \n",
    "                val_losses.append(loss)\n",
    "                \n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            print(\"train_r=\", train_r)\n",
    "            right_ratio = train_r[0] / train_r[1]\n",
    "            \n",
    "            print(\"周期:\",epoch,\"\\tbatch:\",idx,\"\\t训练误差:\",np.mean(losses),\"\\t检验误差:\",np.mean(val_losses),\"\\t准确率:\",\n",
    "                  right_ratio)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "            records.append([np.mean(losses), np.mean(val_losses), 1 - right_ratio])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(records)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('loss/Error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "tests = []\n",
    "\n",
    "for data in zip(test_loader1, test_loader2):\n",
    "    ((x1, y1), (x2, y2)) = data\n",
    "    output = net(Variable(x1), Variable(x2))\n",
    "    label = y1 + y2\n",
    "    test = rightness(output,label)\n",
    "    tests.append(test)\n",
    "\n",
    "rights = (sum([tup[0] for tup in tests]), sum([tup[1] for tup in tests]))\n",
    "right_rate = 1.0*rights[0] / rights[1]\n",
    "print(right_rate)\n",
    "                                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
